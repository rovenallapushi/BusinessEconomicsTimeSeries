---
title: "FuelConsumptionAnalysis"
author: "Llapushi Rovena"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
library(readxl)
library(lmtest) 
library(forecast)
library(DIMORA)
library(urca)
library(ggplot2)
#install.packages("MLmetrics")
library(MLmetrics)
library(mgcv)
#install.packages("mgcv")
library (gbm)
library(data.table)
```

## Load Data

```{r}
fuel_monthly<-read.csv("C:\\Users\\roven\\Desktop\\BEFD Project\\Project_Datasets\\Fuel Price\\Fuel_Price_Monthly.csv")

#setwd("~/BUSINESS ECONOMICAL AND FINANCIAL DATA/Project_Datasets/Fuel Price")
#fuel_monthly<-read.csv("Fuel_Price_Monthly.csv")

benz<-ts(fuel_monthly$Benzina,frequency=12)
gas_a<-ts(fuel_monthly$Gas.Auto,frequency=12)
gas_h<-ts(fuel_monthly$Gas.Heating,frequency=12)
gpl<-ts(fuel_monthly$GPL,frequency=12)
btz_f<-ts(fuel_monthly$BTZ.Fluid,frequency=12)
btz_d<-ts(fuel_monthly$BTZ.Dense,frequency=12)


fuel_cons<-read.csv('C:\\Users\\roven\\Desktop\\BEFD Project\\Project_Datasets\\Fuel Price\\Fuel_consumption_italy_monthly.csv')
#fuel_cons<-read.csv('Fuel_consumption_italy_monthly.csv')
benz_cons<-ts(fuel_cons$Benzina,frequency=12, start=c(2002,1))
gas_auto_cons<-ts(fuel_cons$Gas.Auto,frequency=12, start=c(2002,1))
gas_heat_cons<-ts(fuel_cons$Gas.Heating,frequency=12, start=c(2002,1))
btz_cons<-ts(fuel_cons$BTZ,frequency=12, start=c(2002,1))
gpl_cons<-ts(fuel_cons$GPL,frequency=12, start=c(2002,1))
```



## Benzina

### ARIMA Model

First of all, let's apply the function decompose to Benzina Consumption TS.

```{r decompose benz_cons}
timeseriescomponents <- decompose(benz_cons)
plot(timeseriescomponents)
```

One way to determine more objectively whether differencing is required is to use a unit root test. 
As the value of test is 4.4 we need (not around 0) we can try to differentiate the data to make them stationary.

```{r unit root test benz_cons}
benz_cons %>% ur.kpss() %>% summary()
```
Let's apply the function and see how the test statistic value changes. 
In addition we can carry out how many differences we need to do.
Applying 1 difference to our data we obtain a value of 0.04, closser than the previous one to zero. 
For now, we know that the value of d component for ARIMA Model should be 1.

```{r}
benz_cons %>% diff() %>% ur.kpss() %>% summary()
ndiffs(benz_cons) 
```
After removing the seasonality from our data, we try to plot ACF a nd PACF in order to identify all the other orders required for ARIMA.

Looking at these values we can say from ACF and PACF that we have a p, q = 2, as we applied the first difference d = 1
We use Pacf to determine the AR order of p. looking at our graph we can say that it cuts off after the lag 2 so p = 2
Looking at the ACF we can say that we have 2 important spikes, so q value for the non-seasonal part should be 2;
We have a significant point at lag 12, but nothing repeated at lag 24 so we can conclude for the seasonal part to be 0 the value of p
The seasonal part we can say that we have some peeks at lag 12 and 23, maybe we can use as a value of q =2 for the seasonal part (MA Value)
and of course, the period value should be 12.

```{r}
tsData <- benz_cons

#removing seasonality 
timeseriesseasonallyadjusted <- tsData- timeseriescomponents$seasonal

#applying first difference
tsstationary <- diff(timeseriesseasonallyadjusted, differences=1)

# plot ACF + PACF

Acf(tsstationary) 
Pacf(tsstationary)


```
Let's split the dataset into test and train set. As a test set we will leave out only the data of 2021.

```{r split benz in train and test set}
benz_trainset <- window(benz_cons, start = c(2002,1),end = c(2020,12))
benz_testset  <- window(benz_cons, start = c(2021,01),end = c(2021,12))
```

So, we will apply an ARIMA[2,1,2] [0,1,2] [12] model.

```{r arima model benz cons}

# perform arima model

arimaModel_benz <- arima(benz_trainset, order=c(2,1,2),seasonal = list(order = c(0,1,2), period = 12),method="ML")

# store AIC value

AIC_arimaModel_benz <- AIC(arimaModel_benz)

```
In the next steps, we will fit the model and make the forecast.
From the plot of fitted values we can see that the model is not capturing everything, of course is not performing well on the prediction for Covid period.

```{r fit arima model benz cons}

fitArima_benz_cons <- fitted(arimaModel_benz)

plot(benz_trainset)
lines(fitArima_benz_cons, col=2)

forecast_Arima_benz_cons<- forecast(arimaModel_benz, h = 12)
plot(forecast_Arima_benz_cons)
```

#### Forecasts and predictions 

Referring to the values of MAPE: the model predicted correct 96.5% of our data. The precantage of corrected forecasted values is: 81.1%.
The performance has decreased on the test set. AIC value obtained by this model is: 2246.511

```{r accuracy arima model benz cons}
accuracy_Arima_benz_cons <- accuracy (forecast_Arima_benz_cons, benz_testset)

# store accuracy to create accuracy table
acc_arima_benz_MAPE <- accuracy_Arima_benz_cons[2,][5]
acc_arima_benz_MPE <- accuracy_Arima_benz_cons[2,][4]
acc_arima_benz_MAE <- accuracy_Arima_benz_cons[2,][3]
acc_arima_benz_RMSE <- accuracy_Arima_benz_cons[2,][2]
```
#### Residuals
Looking at the ACF plot we can see that all the spikes are inside the blue dashed line, we can classify them as a white noise series. 
Ljung-Box test p-value: 0.3526

```{r residuals arima model benz cons}
res_benz_cons <- checkresiduals(arimaModel_benz) 

```
### Linear Model

Let's perform linear model on benzina consumption, considering trend and season.
Multiple R-squared:  0.91 (91% of the result is explained by our model).
AIC value: 2647.875. Less then ARIMA performed in the first step.

```{r linear model benz cons}
# linear model

benz_cons_linearModel<- tslm(benz_trainset ~ trend+ season)
summary(benz_cons_linearModel)

# store AIC value

AIC_benz_cons_linearModel <- AIC(benz_cons_linearModel) 

```

In the next steps, we will fit the model and make the forecast.
From the plot of fitted values we can see that the the fitted values are like somehow shifted and not predicting well our data.


```{r fit linear model benz cons}

fit<- fitted(benz_cons_linearModel)

plot(benz_cons)
lines(fitted(benz_cons_linearModel), col=2)


forecast_benz_cons_linearModel <- forecast(benz_cons_linearModel, h = 12)
plot(forecast_benz_cons_linearModel)
```
#### Forecasts and predictions 

What we saw from the plots is evident even by performing the accuracy. Th error on the test set is 30% (as always w.r.t MAPE)

```{r accuracy linear model benz cons}
accuracy_lm_benz_cons  <- accuracy (forecast_benz_cons_linearModel, benz_testset)

# store accuracy to create accuracy table
acc_lm_benz_MAPE <- accuracy_lm_benz_cons[2,][5]
acc_lm_benz_MPE <- accuracy_lm_benz_cons[2,][4]
acc_lm_benz_MAE <- accuracy_lm_benz_cons[2,][3]
acc_lm_benz_RMSE <- accuracy_lm_benz_cons[2,][2]
```
#### Residuals

Plotting the residuals we can say that all the spikes are important, residuals are not white noise.



```{r residuals linear model benz cons}

checkresiduals(benz_cons_linearModel) 


```

What we can do, is to try to model the residuals with auto.arima

```{r fit residuals linear model benz cons}



```
Plot the result

```{r plot arima on residuals and fitted values}

```


### ARMAX XREG = Benz  Price

To continue with the model, we need to get the price of benzine corresponding to the period of consumption.
```{r benz price related to consum}
benz_price_to_consumption<-ts(fuel_monthly$Benzina,frequency=12,start=c(1996,1))
benz_price <- window(benz_price_to_consumption, start=c(2002,1), end=c(2020,12))
benz_price_test <- window(benz_price_to_consumption, start=c(2021,1), end=c(2021,12))
benz_price_full <- window(benz_price_to_consumption, start=c(2002,1), end=c(2021,12))
```

Let's build the model proposed. The model returned is a  Regression with ARIMA(1,0,2)(2,1,1)[12]. AIC value: 2261.95.
Looking at the explanatory variable we added: is is clear that the effect is not strong, or let's say the price is not likely to effect the consumption of this product. It has a negative effect. !!!! add the correct explanation !!! decrease of 4% in consumption for 1 % increase of price. Anyway, we can not say that the impact is almost 0, as the AIC value is something less than on airma model.

```{r arima_model_xreg_benz_price}

auto.arima_benz_price_cons<- auto.arima(benz_trainset, xreg=benz_price)
auto.arima_benz_price_cons

# store AIC Value

AIC_arima_benz_price_cons <- AIC(auto.arima_benz_price_cons)

```

Plotting the fitted values, we can say the model performs better now. Tries to capture the Covid part (at least the decrease in consumption).


```{r fit_arima_model_xreg_benz_price}
# fit and plot the result 
fit_benz_price_cons <- fitted(auto.arima_benz_price_cons)

plot(benz_trainset)
lines(fitted(auto.arima_benz_price_cons), col=2)

#forecast and plot the result

forecast_arima_benz_price_cons <- forecast(auto.arima_benz_price_cons,xreg=benz_price_test, h = 12)
plot(forecast_arima_benz_price_cons)  
```
#### Forecasts and predictions 
Error in test set is around: 33% (worst than the first arima model)


```{r accuracy_arima_modelxreg_benz_price}
accuracy_arima_benz_price_cons <- accuracy(forecast_arima_benz_price_cons, benz_testset)

# store accuracy to create accuracy table

acc_arima_benz_price_MAPE <- accuracy_arima_benz_price_cons[2,][5]
acc_arima_benz_price_MPE <- accuracy_arima_benz_price_cons[2,][4]
acc_arima_benz_price_MAE <- accuracy_arima_benz_price_cons[2,][3]
acc_arima_benz_price_RMSE <- accuracy_arima_benz_price_cons[2,][2]

```



#### Residuals

 There is only one spike outside the blue line, but not so important. Looking at p-value of Ljung-Box test (0.1965) we can conclude that we have white-noise residuals.

```{r residuals_arima_model_xreg_benz_price}

res_arima_benz_price_cons <- checkresiduals(auto.arima_benz_price_cons) 

```


### ARMAX XREG = Gas Auto Consumption

Let's split gas auto consumption in train and test se in order to use it in our model.
We are trying to model benzine consumption having as an explanatory variable the consumption of gas auto.

```{r gas auto cons test and train set}

gas_auto_trainset <- window(gas_auto_cons, start=c(2002,1), end=c(2020,12))
gas_auto_testset <- window(gas_auto_cons, start=c(2021,1), end=c(2021,12))
gas_auto_full <- window(gas_auto_cons, start=c(2002,1), end=c(2021,12))
```

Let's build the model, so we can better understand the impact of gas auto consumption to our dependent variable.
Well, we obtain an AIC value of 1929.69, the best seen so far. This is supported even by the the coefficient of explanatory variable. 
We have an impact of 36%  ... !!!! continue !!!!

```{r arima_model_xreg_gas_auto_cons}

auto.arima_benz_price_gas_auto<- auto.arima(benz_trainset, xreg=gas_auto_trainset)
auto.arima_benz_price_gas_auto

AIC_arima_benz_price_gas_auto <- AIC(auto.arima_benz_price_gas_auto)

```

We move one with the fitting and forecasting procedure. As we expected, the values fits quite well on the train set and models very well even the Covid part.

```{r fit arima model xreg gas_auto_cons}
# fit and plot the result
fit_benz_price_gas_auto <- fitted(auto.arima_benz_price_gas_auto)

plot(benz_trainset)
lines(fitted(auto.arima_benz_price_gas_auto), col=2)

# forecast and plot the result

forecast_arima_benz_price_gas_auto <- forecast(auto.arima_benz_price_gas_auto,xreg=gas_auto_testset, h = 12)
plot(forecast_arima_benz_price_gas_auto)

```


#### Forecasts and predictions 

Looking at the values of MAPE, the last model proposed makes an error of 7.5 % on test set and just 1.9 % in the train set.


```{r accuracy arima model xreg  gas_auto_cons}

accuracy_arima_benz_gas_auto_cons <- accuracy (forecast_arima_benz_price_gas_auto, benz_testset)

# store accuracy to create accuracy table

acc_arima_benz_gas_auto_cons_MAPE <- accuracy_arima_benz_gas_auto_cons[2,][5]
acc_arima_benz_gas_auto_cons_MPE <- accuracy_arima_benz_gas_auto_cons[2,][4]
acc_arima_benz_gas_auto_cons_MAE <- accuracy_arima_benz_gas_auto_cons[2,][3]
acc_arima_benz_gas_auto_cons_RMSE <- accuracy_arima_benz_gas_auto_cons[2,][2]
```

#### Residuals

Even that we have 2 spikes at lag 11 and 30, looking at Ljung-Box test we can say that the residuals are white noise.

```{r residuals arima model xreg  gas_auto_cons}

res_benz_cons_linearModel <- checkresiduals(auto.arima_benz_price_gas_auto) 
```


### Exponential Smoothing 

Here, we will apply the ETS function, which allows us to find errors, trend, and seasonality. This function provides a completely automatic way of producing forecasts. AIC value obtained by this model is: 3024.054. Looking at the summary, we get an information about the error percentage on training set which is about 4.8%.

```{r expo smoothing benz_cons}

es_benz_cons_model <- ets(benz_trainset)  
summary(es_benz_cons_model)

AIC_es_benz_cons_model <- AIC(es_benz_cons_model)

```

Let's try to fit and forecast the model. Looking at the fitted values, seems that is able to capture the shape of our data,expect Covid period.


```{r fit expo smoothing benz_cons}
# fit and plot the result 
fit_es_benz_cons_model <- fitted(es_benz_cons_model)

plot(benz_trainset)
lines(fitted(es_benz_cons_model), col=2)

#forecast and plot the result

forecast_es_benz_cons_model <- forecast(es_benz_cons_model, h = 12)
plot(forecast_es_benz_cons_model) 
```

#### Forecasts and predictions 

```{r accuracy expo smoothing benz_cons}
accuracy_es_benz_cons <- accuracy (forecast_es_benz_cons_model, benz_testset)

# store accuracy to create accuracy table

acc_es_benz_cons_MAPE <- accuracy_es_benz_cons[2,][5]
acc_es_benz_cons_MPE <- accuracy_es_benz_cons[2,][4]
acc_es_benz_cons_MAE <- accuracy_es_benz_cons[2,][3]
acc_es_benz_cons_RMSE <- accuracy_es_benz_cons[2,][2]

```

#### Residuals

We have important spikes at lag 1 and 4. Also, Ljung-Box confirms that the residuals are not white noise.

```{r residuals expo smoothing benz_cons}

checkresiduals(es_benz_cons_model)

```

### GAM MODEL

Looking at the plots we can clearly see an increase until July, for which we have the peak of the consumption.
From August until November we have a decrease, but it doesn't reach the low point of consumption on February. As expected, during December we have an increase on consumption. Looking at the plot of Year, we can say that there is a slow decrease of consumption. It reaches a minimum on 2017 and of course during lock-down. After plotting our model, we need to do the diagnostic pf our first model. Some of the indicators we need to take a look are:
     * EDF - the level of smoothness of one variable. For both of variables we have a complex splines.
     * p- value: both of variables have a lower p-value, meaning they are both significant. Moreover, the non linearity of our model is quite        important.
     * R-sq. = 97% of benzine consumption is explained by our model.

```{r benz cons data}

# prepare benzine data frame to use in GAM model
benz.month <- c(month(as.Date(as.yearmon(fuel_cons$Date))))
benz.year <- c(year(as.Date(as.yearmon(fuel_cons$Date))))
benz.consumption <- c(fuel_cons$Benzina)
benz.Monthyear  <- c(as.Date(as.yearmon(fuel_cons$Date)))
benz <- data.frame(benz.month ,benz.year, benz.consumption, benz.Monthyear)

# divide in train and test set 

benz.train <- benz
benz.test <- subset(benz,benz.year = 2021 )

# create first model of GAM and plot it 

g1 <- gam (benz.consumption ~ s(benz.month) + s(benz.year, k = 12), data = benz.train, family = gaussian )

plot(g1, shade = TRUE, shade.col = "lightblue")

# Let's use summary to do the diagnostic of our first model:

summary(g1)


```

Below we plotted fitted and real values. Looks like the model is capturing every pattern (despite Covid part)

```{r plot GAM benz_cons}
# fit and plot the result 

datas <- rbindlist(list( data.table(value =  benz.train$benz.consumption,
                                   data_time = benz.train$benz.Monthyear),
                        data.table(value = g1$fitted.values,
                                   data_time = benz.train$benz.Monthyear)))

datas[, type := c(rep("Real", nrow(benz.train)), rep("Fitted", nrow(benz.train)))]
 
ggplot(data = datas, aes(data_time, value, group = type, colour = type)) +
  geom_line(size = 0.8) +
  theme_bw() +
  labs(x = "Time", y = "Benzine Consumprion",
       title = "Fit from GAM n.1")
```

What we can try next is to use one smoothing function to both variables used in this model (like using an intersection of both variables).
How can we compare this model to the first one? Let's start with R.sq value. Here is 1% less. Looking at p-value, this intersection is significant. We can try to plot fitted values to check better the result.


```{r gam second model}
# create second model of GAM and plot it 

g2 <- gam (benz.consumption ~ s(benz.month, benz.year), data = benz.train, family = gaussian )

plot(g2, shade = TRUE, shade.col = "lightblue")

# Let's use summary to do the diagnostic of our first model:

summary(g2)
```

Well, the plot is quite the same as the previous model. The second model fails on the prediction of 2019 consumption.


```{r plot second GAM model benz_cons}


# fit and plot the result 

datas2 <- rbindlist(list( data.table(value =  benz.train$benz.consumption,
                                   data_time = benz.train$benz.Monthyear),
                        data.table(value = g2$fitted.values,
                                   data_time = benz.train$benz.Monthyear)))

datas2[, type := c(rep("Real", nrow(benz.train)), rep("Fitted", nrow(benz.train)))]
 
ggplot(data = datas2, aes(data_time, value, group = type, colour = type)) +
  geom_line(size = 0.8) +
  theme_bw() +
  labs(x = "Time", y = "Benzine Consumprion",
       title = "Fit from GAM n.2")

```

Now, we will try to add another variable on our model, using month and year as separate variables.
Looking at p-value, form the summary of this model, we can say that the price of benzine has no significant impact on the prediction of the consumption. We expected this result. Anyway, let's plot the fitted values.

```{r gam third model}

# create third model of GAM and plot it 

g3 <- gam (benz.consumption ~ s(benz.month) + s(benz.year) + s(benz_price_full), data = benz.train, family = gaussian )

plot(g3, shade = TRUE, shade.col = "lightblue")

# Let's use summary to do the diagnostic of our first model:

summary(g3)
```

Looking at the plot, it doesn't fit bad, but looks like the other plots done so far.

```{r plot third GAM model benz_cons}


# fit and plot the result 

datas3 <- rbindlist(list( data.table(value =  benz.train$benz.consumption,
                                   data_time = benz.train$benz.Monthyear),
                        data.table(value = g3$fitted.values,
                                   data_time = benz.train$benz.Monthyear)))

datas3[, type := c(rep("Real", nrow(benz.train)), rep("Fitted", nrow(benz.train)))]
 
ggplot(data = datas3, aes(data_time, value, group = type, colour = type)) +
  geom_line(size = 0.5) +
  theme_bw() +
  labs(x = "Time", y = "Benzine Consumprion",
       title = "Fit from GAM n.3")

```

Now, we will try to use as an explanatory variable the consumption of gas_auto.
We obtain the highest R2 value seen so far : 99%. Again we confirm what we found in the previous models. The significance of smooth term added is important. Looking at the plot we can see an increase of  !!! add interpretation !!!!

```{r gam fourth model}

# create third model of GAM and plot it 

g4 <- gam (benz.consumption ~ s(benz.month) + s(benz.year) + s(gas_auto_cons), data = benz.train, family = gaussian )

plot(g4, shade = TRUE, shade.col = "lightblue")

# Let's use summary to do the diagnostic of our first model:

summary(g4)
```

As expected, even from other models, fails to predict only Covid period.

```{r plot fourth GAM model benz_cons}


# fit and plot the result 

datas4 <- rbindlist(list( data.table(value =  benz.train$benz.consumption,
                                   data_time = benz.train$benz.Monthyear),
                        data.table(value = g4$fitted.values,
                                   data_time = benz.train$benz.Monthyear)))

datas4[, type := c(rep("Real", nrow(benz.train)), rep("Fitted", nrow(benz.train)))]
 
ggplot(data = datas4, aes(data_time, value, group = type, colour = type)) +
  geom_line(linewidth= 0.5) +
  theme_bw() +
  labs(x = "Time", y = "Benzine Consumprion",
       title = "Fit from GAM n.4")
```

How can we select the best model from the ones proposed using GAM?
We can use AIC. Let's summarize the values: As expected, the best model is the last one, which has the lowest AIC value. The next step, is to use gam.check function which makes four plots:

   1. QQ-plot of residuals
   2. linear predictor vs. residuals
   3. histogram of residuals 
   4. fitted vs. response


```{r GAM model summary benz cons}

AIC(g1, g2, g3, g4)

```
We expect to have residuals close too a straight line. We can say that the residuals of this model are not bad. Looking at the histogram, it has a left tail. On the last plot, we expect to have a straight line, in our case is close to it.
```{r check best gam model benz cons }
```


```{r check best gam model benz cons }
gam.check(g4)
```



```{r gam fourth model different k for month}

# create third model of GAM and plot it 

g4.1 <- gam (benz.consumption ~ s(benz.month, k = 8) + s(benz.year, k = 10) + s(gas_auto_cons), data = benz.train, family = gaussian )

plot(g4.1, shade = TRUE, shade.col = "lightblue")

# Let's use summary to do the diagnostic of our first model:

summary(g4.1)
```
```{r check new gam model benz cons }
gam.check(g4.1)
```


### Summarizing all the models

```{r}
# AIC plus accuracy table Benzina 

benz_summary <- matrix(c(
  AIC_arimaModel_benz,AIC_benz_cons_linearModel, AIC_arima_benz_price_cons, AIC_arima_benz_price_gas_auto,AIC_es_benz_cons_model,
  acc_arima_benz_MAPE,acc_lm_benz_MAPE,acc_arima_benz_price_MAPE,acc_arima_benz_gas_auto_cons_MAPE,acc_es_benz_cons_MAPE,
  acc_arima_benz_MPE,acc_lm_benz_MPE,acc_arima_benz_price_MPE,acc_arima_benz_gas_auto_cons_MPE,acc_es_benz_cons_MPE,
  acc_arima_benz_MAE,acc_lm_benz_MAE,acc_arima_benz_price_MAE,acc_arima_benz_gas_auto_cons_MAE,acc_es_benz_cons_MAE,
  acc_arima_benz_RMSE,acc_lm_benz_RMSE,acc_arima_benz_price_RMSE,acc_arima_benz_gas_auto_cons_RMSE,acc_es_benz_cons_RMSE), ncol = 5, byrow =TRUE)

colnames(benz_summary) <- c('Arima','Linear Model','SARMAX Price', 'SARMAX GasAuto', 'ES')
rownames(benz_summary) <- c('AIC', 'MAPE','MPE','MAE','RMSE')

benz_summary <- as.table(benz_summary)
benz_summary

```


## Gas Auto

Before starting the analysis, let's split the dataset into train and test set.

```{r gas auto split dataset}

gas_auto_trainset  <- window(gas_auto_cons, start = c(2002,01),end = c(2020,12))
gas_auto_testset  <- window(gas_auto_cons, start = c(2021,01),end = c(2021,12))


```

### Linear Model

We start applying linear model, as a baseline. Looking at R-squared:  0.3126, seems that this model will not model correctly the data.
Let's try to perform all the steps and see the results. Also, the AIC value for this model is: 2998.344.
```{r lm gas auto}

#Linear Model and summary

gas_auto_linearModel <- tslm(gas_auto_trainset ~ trend+season)
summary(gas_auto_linearModel) 

# store AIC Value
AIC_lm_gas_auto <- AIC(gas_auto_linearModel)

```
As expected, looking at fitted values plot, there is a huge difference between values. Therefore, we will expect a high rate of errors.


```{r fit lm gas auto}
# fit and plot the result 

fit_gas_auto<- fitted(gas_auto_linearModel)

plot(gas_auto_trainset)
lines(fitted(gas_auto_linearModel), col=2)

#forecast and plot the result

forecast_lm_gas_auto  <- forecast(gas_auto_linearModel, h = 12)
plot(forecast_lm_gas_auto)  

```

#### Forecasts and predictions

Well, this result is a little bit surprising. We obtain an error at level 6% on both train and test set.

```{r accuracy lm gas auto}

accuracy_lm_gas_auto <- accuracy(forecast_lm_gas_auto, gas_auto_testset)

# store accuracy to create accuracy table

acc_lm_gas_auto_MAPE <- accuracy_lm_gas_auto[2,][5]
acc_lm_gas_auto_MPE <- accuracy_lm_gas_auto[2,][4]
acc_lm_gas_auto_MAE <- accuracy_lm_gas_auto[2,][3]
acc_lm_gas_auto_RMSE <- accuracy_lm_gas_auto[2,][2]


```

#### Residuals

Looking at residuals we can conclude that they are not white noise.


```{r residuals lm gas auto}

res_lm_gas_auto <- checkresiduals(gas_auto_linearModel) 

```


### Arima Model

The next model we will try to model this time series is Arima. AIC value we obtain is: 2826.11. Better than Linear Model.

```{r arima gas auto}

#Linear Model and summary

arima.gas_auto <- auto.arima(gas_auto_trainset)
summary(arima.gas_auto) 

# store AIC Value
AIC_arima.gas_auto <- AIC(arima.gas_auto)

```

From the plots we can understand that the model capture well some patterns. Interesting enough is the fact of forecasting data the same as during "Covid" period. Here, we can realize the strong effect of Covid period.

```{r fit arima gas auto}
# fit and plot the result 

fit_arima.gas_auto<- fitted(arima.gas_auto)

plot(gas_auto_trainset)
lines(fitted(arima.gas_auto), col=2)

#forecast and plot the result

forecast_arima.gas_auto <- forecast(arima.gas_auto, h = 12)
plot(forecast_arima.gas_auto)  

```

#### Forecasts and predictions

We obtain an error of 4% on the train set and 23% on the test set.

```{r accuracy arima gas auto}

accuracy_arima_gas_auto <- accuracy(forecast_arima.gas_auto, gas_auto_testset)

# store accuracy to create accuracy table

acc_arima_gas_auto_MAPE <- accuracy_arima_gas_auto[2,][5]
acc_arima_gas_auto_MPE <- accuracy_arima_gas_auto[2,][4]
acc_arima_gas_auto_MAE <- accuracy_arima_gas_auto[2,][3]
acc_arima_gas_auto_RMSE <- accuracy_arima_gas_auto[2,][2]
```

#### Residuals

Plotting the residuals: we have a spike on lag 24 but it's value is not high to be considered. Consulting Ljung-box test we can say they represent white noise series.


```{r residuals arima gas auto}

res_arima_gas_auto <- checkresiduals(arima.gas_auto) 

```




### Armax with xreg = gas_auto_price

As we did for benzine series, we will try to explain the consumption of gas auto using the effect of it's price.
Let's first fetch the price of Gas auto for the period we have the values of Consumption.

```{r gas auto price consum}
gas_auto_price_to_consumption<-ts(fuel_monthly$Gas.Auto,frequency=12,start=c(1996,1))
gas_auto_price <- window(benz_price_to_consumption, start=c(2002,1), end=c(2020,12))
gas_auto_price_test <- window(benz_price_to_consumption, start=c(2021,1), end=c(2021,12))
```

Looking at the results we can say: 11% of .... continue
AIC value for this model is: 2827.33. Very close to Arima model without any explanatory variable. 
```{r armax gas auto xreg  price}

#Armax model and summary

arima.gas_auto_price <- auto.arima(gas_auto_trainset, xreg = gas_auto_price)
summary(arima.gas_auto_price) 

# store AIC Value
AIC_arima.gas_auto_price <- AIC(arima.gas_auto_price)

```

At the first sight the plots are very similiar to the one produced by Arima model.

```{r fit armax gas auto xreg  price}
# fit and plot the result 

fit_arima.gas_auto_price <- fitted(arima.gas_auto_price)

plot(gas_auto_trainset)
lines(fitted(arima.gas_auto_price), col=2)

#forecast and plot the result

forecast_arima.gas_auto_price <- forecast(arima.gas_auto_price,xreg = gas_auto_price_test, h = 12)
plot(forecast_arima.gas_auto_price)  

```

#### Forecasts and predictions

We obtain an error of 4% on the train set (as in the previous model) and 21% on the test set (2% less than arima model)

```{r accuracy armax gas auto xreg  price}

accuracy_arima.gas_auto_price <- accuracy(forecast_arima.gas_auto_price, gas_auto_testset)

# store accuracy to create accuracy table

acc_arima_gas_auto_price_MAPE <- accuracy_arima.gas_auto_price[2,][5]
acc_arima_gas_auto_price_MPE <- accuracy_arima.gas_auto_price[2,][4]
acc_arima_gas_auto_price_MAE <- accuracy_arima.gas_auto_price[2,][3]
acc_arima_gas_auto_price_RMSE <- accuracy_arima.gas_auto_price[2,][2]

```

#### Residuals

Plotting the residuals: we have a spike on lag 24 but it's value is not high to be considered. Consulting Ljung-box test we can say they represent white noise series (the same as in Arima model). We con conclude that the effect of price on the consumption is not significant, so is useless to try to perform a lindear model with price as explanatory variable.


```{r residuals arima gasgauto}

res_arima_gas_auto <- checkresiduals(arima.gas_auto_price) 

```


### Exponential Smoothing 

Here, we will apply the ETS function. AIC value obtained by this model is: 3436.91. Looking at the summary, we get an information about the error percentage on training set which is about 4.3%.

```{r expo smoothing gas auto}

es_gas_auto_cons_model <- ets(gas_auto_trainset)  
summary(es_gas_auto_cons_model)

AIC_es_gas_auto_cons_model <- AIC(es_gas_auto_cons_model)

```

Let's try to fit and forecast the model. Looking at the fitted values, seems that is able to capture the shape of our data, also period.


```{r fit expo smoothing gas auto}
# fit and plot the result 
fit_gas_auto_cons_model <- fitted(es_gas_auto_cons_model)

plot(gas_auto_trainset)
lines(fitted(es_gas_auto_cons_model), col=2)

#forecast and plot the result

forecast_es_gas_auto_cons_model <- forecast(es_gas_auto_cons_model, h = 12)
plot(forecast_es_gas_auto_cons_model) 
```

#### Forecasts and predictions 


According to the accuracy the error on test set is around 11.9% and in test set: 4.3 %.

```{r accuracy expo smoothing gas auto}
accuracy_es_benz_cons <- accuracy (forecast_es_gas_auto_cons_model, gas_auto_testset)

# store accuracy to create accuracy table

acc_es_gas_auto_cons_MAPE <- accuracy_es_benz_cons[2,][5]
acc_es_gas_auto_cons_MPE <- accuracy_es_benz_cons[2,][4]
acc_es_gas_auto_cons_MAE <- accuracy_es_benz_cons[2,][3]
acc_es_gas_auto_cons_RMSE <- accuracy_es_benz_cons[2,][2]
```

#### Residuals

We have important spikes at lag 2, 4 and 27. Also, Ljung-Box confirms that the residuals are not white noise. !!! double check !!!

```{r residuals expo smoothing gas auto}

checkresiduals(es_gas_auto_cons_model)

```


### GAM MODEL

Add comment for GAM MODEL. AIC Value 2867.846;

```{r GAM gasauto}
tt<- (1:length(gas_auto_trainset))
seas <- factor(c(rep(1:12,length(gas_auto_trainset)/12)))

g1 <- gam(gas_auto_trainset~s(tt)+seas)

plot(g1, se=T)

AIC(g1)

```


### Summarizing all the models

```{r summary gas auto}
# AIC plus accuracy table Gas Auto 

gas_auto_summary <- matrix(c(
  AIC_arima.gas_auto,AIC_lm_gas_auto,AIC_arima.gas_auto_price, AIC_es_gas_auto_cons_model,
  acc_arima_gas_auto_MAPE,acc_lm_gas_auto_MAPE,acc_arima_gas_auto_price_MAPE,acc_es_gas_auto_cons_MAPE,
  acc_arima_gas_auto_MPE,acc_lm_gas_auto_MPE,acc_arima_gas_auto_price_MPE,acc_es_gas_auto_cons_MPE,
  acc_arima_gas_auto_MAE,acc_lm_gas_auto_MAE,acc_arima_gas_auto_price_MAE,acc_es_gas_auto_cons_MAE,
  acc_arima_gas_auto_RMSE,acc_lm_gas_auto_RMSE,acc_arima_gas_auto_price_RMSE,acc_es_gas_auto_cons_RMSE), ncol = 4, byrow =TRUE)

colnames(gas_auto_summary) <- c('Arima','Linear Model','SARMAX Price', 'ES')
rownames(gas_auto_summary) <- c('AIC', 'MAPE','MPE','MAE','RMSE')

gas_auto_summary <- as.table(gas_auto_summary)
gas_auto_summary

```




## GPL

Before starting the analysis, let's split the dataset into train and test set.

```{r gpl split dataset}

gpl_trainset  <- window(gpl_cons, start = c(2002,01),end = c(2020,12))
gpl_testset  <- window(gpl_cons, start = c(2021,01),end = c(2021,12))


```

### Linear Model

We start applying linear model, as a baseline. Looking at R-squared:  0.80.
Let's try to perform all the steps and see the results. Also, the AIC value for this model is: 2174.71.
```{r lm gpl}

#Linear Model and summary

gpl_linearModel <- tslm(gpl_trainset ~ trend+season)
summary(gpl_linearModel) 

# store AIC Value
AIC_gpl_linearModel <- AIC(gpl_linearModel)

```

Looking at the plot, our model is good at capturing the increase part of each season, it fails when predicting the lowest point of the consumption.


```{r fit lm gpl}
# fit and plot the result 

fit_gpl_linearModel <- fitted(gpl_linearModel)

plot(gpl_trainset)
lines(fitted(gpl_linearModel), col=2)

#forecast and plot the result

forecast_lm_gpl  <- forecast(gpl_linearModel, h = 12)
plot(forecast_lm_gpl)  

```

#### Forecasts and predictions

Well, this result is a little bit surprising. We obtain an error at level 9.3 % on test set and 2 % less on test set.

```{r accuracy lm gpl}

accuracy_lm_gpl <- accuracy(forecast_lm_gpl, gpl_testset)

# store accuracy to create accuracy table

acc_lm_gpl_MAPE <- accuracy_lm_gpl[2,][5]
acc_lm_gpl_MPE <- accuracy_lm_gpl[2,][4]
acc_lm_gpl_MAE <- accuracy_lm_gpl[2,][3]
acc_lm_gpl_RMSE <- accuracy_lm_gpl[2,][2]
```

#### Residuals

Residuals non white noise.

!!!! check and fit them !!!!


```{r residuals lm gpl}

res_lm_gpl <- checkresiduals(gpl_linearModel ) 

```


### Arima Model

The next model we will try to model this time series is Arima. AIC value we obtain is: 1989.25. Better than Linear Model.

```{r arima gpl}

#Linear Model and summary

auto.arima_gpl_cons <- auto.arima(gpl_trainset)
summary(auto.arima_gpl_cons) 

# store AIC Value
AIC_arima.gpl <- AIC(auto.arima_gpl_cons)

```

From the plots we can understand that the model captures almost everything from the time series.

```{r fit arima gpl}
# fit and plot the result 

fitArima_gpl_cons<- fitted(auto.arima_gpl_cons)

plot(gpl_trainset)
lines(fitArima_gpl_cons, col=2)

#forecast and plot the result

forecast_Arima_gpl_cons <- forecast(fitArima_gpl_cons, h = 12)
plot(forecast_Arima_gpl_cons)

```

#### Forecasts and predictions

We obtain an error of 4% on the train set and 6% on the test set.

```{r accuracy arima gpl}

accuracy_arima_gpl <- accuracy (forecast_Arima_gpl_cons, gpl_testset)

# store accuracy to create accuracy table

acc_arima_gpl_MAPE <- accuracy_arima_gpl[2,][5]
acc_arima_gpl_MPE <- accuracy_arima_gpl[2,][4]
acc_arima_gpl_MAE <- accuracy_arima_gpl[2,][3]
acc_arima_gpl_RMSE <- accuracy_arima_gpl[2,][2]

```

#### Residuals

Plotting the residuals: we have 2 spikes (lag 2 and 19) but it's value is not high to be considered. Consulting Ljung-box test we can say they represent non white noise series.

!!!! fit residuals !!!

```{r residuals arima gpl}

res_gpl_cons <- checkresiduals(auto.arima_gpl_cons) 

```




### Armax with xreg = gpl_price

As we did for benzine series, we will try to explain the consumption of GPL  using the effect of it's price.
Let's first fetch the price of GPL for the period we have the values of Consumption.

```{r gas auto price related to consum}
gpl_price_to_consumption<-ts(fuel_monthly$GPL,frequency=12,start=c(1996,1))
gpl_price <- window(gpl_price_to_consumption, start=c(2002,1), end=c(2020,12))
gpl_price_test <- window(gpl_price_to_consumption, start=c(2021,1), end=c(2021,12))
```

Looking at the results we can say: 5% of .... continue
AIC value for this model is: 1988.62. Very close to Arima model without any explanatory variable. 
```{r armax gpl xreg  price}

#Armax model and summary

auto.arima_gpl_price_cons<- auto.arima(gpl_trainset, xreg=gpl_price)
summary(auto.arima_gpl_price_cons)

# store AIC Value
AIC_arima.gpl_price <- AIC(auto.arima_gpl_price_cons)

```

At the first sight the plots are very similiar to the one produced by Arima model.

```{r fit armax gpl xreg price}
# fit and plot the result 

fit_gpl_price_cons <- fitted(auto.arima_gpl_price_cons)

plot(gpl_trainset)
lines(fitted(auto.arima_gpl_price_cons), col=2)

#forecast and plot the result

forecast_arima_gpl_price_cons <- forecast(auto.arima_gpl_price_cons,xreg=gpl_price_test, h = 12)
plot(forecast_arima_gpl_price_cons) 

```

#### Forecasts and predictions

We obtain an error of 5.5% on the train set (1% more than arima model) and 8.7% on the test set (2% more than arima model)

```{r accuracy armax gpl xreg  price}

accuracy_arima.gpl_price <- accuracy (forecast_arima_gpl_price_cons, gpl_testset)

# store accuracy to create accuracy table

acc_arima_gpl_price_MAPE <- accuracy_arima.gpl_price[2,][5]
acc_arima_gpl_price_MPE <- accuracy_arima.gpl_price[2,][4]
acc_arima_gpl_price_MAE <- accuracy_arima.gpl_price[2,][3]
acc_arima_gpl_price_RMSE <- accuracy_arima.gpl_price[2,][2]

```

#### Residuals

Plotting the residuals: we have a spike on lag 19. Consulting Ljung-box test we can say they does not represent white noise series.  


```{r residuals armax gpl xreg  price}

res_arima_gpl <- checkresiduals(auto.arima_gpl_price_cons) 

```


### Exponential Smoothing 

Here, we will apply the ETS function. AIC value obtained by this model is: 2647.876. Looking at the summary, we get an information about the error percentage on training set which is about 5.9%.

```{r expo smoothing gpl}

es_gpl_cons_model <- ets(gpl_trainset)  
summary(es_gpl_cons_model)

AIC_es_gpl_cons_model <- AIC(es_gpl_cons_model)

```

Let's try to fit and forecast the model. Looking at the fitted values, seems that is able to capture the shape of our data, also Covid period.


```{r fit expo smoothing gpl}
# fit and plot the result 
fit_gpl_cons_model <- fitted(es_gpl_cons_model)

plot(gpl_trainset)
lines(fitted(es_gpl_cons_model), col=2)

#forecast and plot the result

forecast_es_gpl_cons_model <- forecast(es_gpl_cons_model, h = 12)
plot(forecast_es_gpl_cons_model)
```

#### Forecasts and predictions 


According to the accuracy the error on test set is around 5.9% and in test set: 7.3 %.

```{r accuracy expo smoothing gpl}
accuracy_es_gpl_cons <- accuracy (forecast_es_gpl_cons_model, gpl_testset)

# store accuracy to create accuracy table

acc_es_gpl_cons_MAPE <- accuracy_es_gpl_cons[2,][5]
acc_es_gpl_cons_MPE <- accuracy_es_gpl_cons[2,][4]
acc_es_gpl_cons_MAE <- accuracy_es_gpl_cons[2,][3]
acc_es_gpl_cons_RMSE <- accuracy_es_gpl_cons[2,][2]
```

#### Residuals

We have important spikes at lag 1, 4 and 19. Also, Ljung-Box confirms that the residuals are not white noise. !!! double check !!!

```{r residuals expo smoothing gpl}

checkresiduals(es_gpl_cons_model)

```


### GAM MODEL

Add comment for GAM MODEL. AIC Value 2139.363;

```{r GAM gas auto}
tt<- (1:length(gpl_trainset))
seas <- factor(c(rep(1:12,length(gpl_trainset)/12)))

g1 <- gam(gpl_trainset~s(tt)+seas)

plot(g1, se=T)

AIC(g1)

```


### Summarizing all the models

```{r summary gpl}
# AIC plus accuracy table GPL

gpl_summary <- matrix(c(
  AIC_arima.gpl,AIC_gpl_linearModel, AIC_arima.gpl_price,AIC_es_gpl_cons_model,
  acc_arima_gpl_MAPE,acc_lm_gpl_MAPE,acc_arima_gpl_price_MAPE,acc_es_gpl_cons_MAPE,
  acc_arima_gpl_MPE,acc_lm_gpl_MPE,acc_arima_gpl_price_MPE,acc_es_gpl_cons_MPE,
  acc_arima_gpl_MAE,acc_arima_gpl_price_MAE,acc_arima_gpl_price_MAE,acc_es_gpl_cons_MAE,
  acc_arima_gpl_RMSE,acc_lm_gpl_RMSE,acc_arima_gpl_price_RMSE,acc_es_gpl_cons_RMSE
  ), ncol = 4, byrow =TRUE)

colnames(gpl_summary) <- c('Arima','Linear Model','SARMAX Price', 'ES')
rownames(gpl_summary) <- c('AIC', 'MAPE','MPE','MAE','RMSE')

gpl_summary <- as.table(gpl_summary)
gpl_summary

```





## GAS HEATING

Before starting the analysis, let's split the dataset into train and test set.

```{r gas_heat split dataset}

gas_heat_trainset  <- window(gas_heat_cons, start = c(2002,01),end = c(2020,12))
gas_heat_testset  <- window(gas_heat_cons, start = c(2021,01),end = c(2021,12))

```

### Linear Model

We start applying linear model, as a baseline. Looking at R-squared:  0.83.
Let's try to perform all the steps and see the results. Also, the AIC value for this model is: 2419.094.
```{r lm gas_heat}

#Linear Model and summary

gas_heat_linearModel <- tslm(gas_heat_trainset ~ trend+season)
summary(gas_heat_linearModel) 

# store AIC Value
AIC_gas_heat_linearModel <- AIC(gas_heat_linearModel)

```

Looking at the plot, our model is good at capturing the increase part of each season, it fails when predicting the lowest point of the consumption.


```{r fit lm gas_heat}
# fit and plot the result 

fit_lm_gas_heat<- fitted(gas_heat_linearModel)

plot(gas_heat_trainset)
lines(fitted(gas_heat_linearModel), col=2)

#forecast and plot the result

forecast_gas_heat_linearModel <- forecast(gas_heat_linearModel, h = 12)
plot(forecast_gas_heat_linearModel)

```

#### Forecasts and predictions

Well, this result is a little bit surprising. We obtain an error at level 131.4 % on test set and  41.5 % less on train set.

```{r accuracy lm gas_heat}

accuracy_lm_gas_heat <- accuracy(forecast_gas_heat_linearModel, gas_heat_testset)

# store accuracy to create accuracy table

acc_lm_gas_heat_MAPE <- accuracy_lm_gas_heat[2,][5]
acc_lm_gas_heat_MPE <- accuracy_lm_gas_heat[2,][4]
acc_lm_gas_heat_MAE <- accuracy_lm_gas_heat[2,][3]
acc_lm_gas_heat_RMSE <- accuracy_lm_gas_heat[2,][2]
```

#### Residuals

Residuals non white noise.

!!!! check and fit them !!!!


```{r residuals lm gas_heat}

res_lm_gpl <- checkresiduals(gas_heat_linearModel) 

```


### Arima Model

The next model we will try to model this time series is Arima. AIC value we obtain is: 2013.96. Better than Linear Model.

```{r arima gas_heat}

#Linear Model and summary

auto.arima_gas_heat_cons <- auto.arima(gas_heat_trainset)
auto.arima_gas_heat_cons

# store AIC Value
AIC_arima.gas_heat <- AIC(auto.arima_gas_heat_cons)

```

From the plots we can understand that the model captures almost everything from the time series.

```{r fit arima gas_heat}
# fit and plot the result 

fitArima_gas_heat_cons <- fitted(auto.arima_gas_heat_cons)

plot(gas_heat_trainset)
lines(fitArima_gas_heat_cons, col=2)

#forecast and plot the result

forecast_Arima_gas_heat_cons<- forecast(fitArima_gas_heat_cons, h = 12)
plot(forecast_Arima_gas_heat_cons)

```

#### Forecasts and predictions

We obtain an error of 13.8% on the train set and 15% on the test set.

```{r accuracy arima gas_heat}

accuracy_arima_gas_heat <- accuracy (forecast_Arima_gas_heat_cons, gas_heat_testset )

# store accuracy to create accuracy table

acc_arima_gas_heat_MAPE <- accuracy_arima_gas_heat[2,][5]
acc_arima_gas_heat_MPE <- accuracy_arima_gas_heat[2,][4]
acc_arima_gas_heat_MAE <- accuracy_arima_gas_heat[2,][3]
acc_arima_gas_heat_RMSE <- accuracy_arima_gas_heat[2,][2]

```

#### Residuals

Plotting the residuals: we have a spike at lag 19 but it's value is not high to be considered. Consulting Ljung-box test we can say they represent a white noise series.

!!!! fit residuals !!!

```{r residuals arima gas_auto}

res_gas_heat_cons <- checkresiduals(auto.arima_gas_heat_cons) 

```




### Armax with xreg = gas_heat_price

As we did for benzine series, we will try to explain the consumption of GPL  using the effect of it's price.
Let's first fetch the price of GPL for the period we have the values of Consumption.

```{r gas heat price related to consum}
gas_heat_price_to_consumption<-ts(fuel_monthly$Gas.Heating,frequency=12,start=c(1996,1))
gas_heat_price <- window(gas_heat_price_to_consumption, start=c(2002,1), end=c(2020,12))
gas_heat_price_test <- window(gas_heat_price_to_consumption, start=c(2021,1), end=c(2021,12))
```

Looking at the results we can say: 2% of .... continue
AIC value for this model is: 2014.46. Very close to Arima model without any explanatory variable. 
```{r armax gas_heat xreg price}

#Armax model and summary

auto.arima_gas_heat_price_cons<- auto.arima(gas_heat_trainset, xreg=gas_heat_price) 
auto.arima_gas_heat_price_cons

# store AIC Value
AIC_arima.gas_heat_price <- AIC(auto.arima_gas_heat_price_cons)

```

At the first sight the plots are very similiar to the one produced by Arima model.

```{r fit armax gas_heat xreg  price}
# fit and plot the result 

fit_gas_heat_price_cons <- fitted(auto.arima_gas_heat_price_cons)
plot(gas_heat_trainset)
lines(fitted(auto.arima_gas_heat_price_cons), col=2)

#forecast and plot the result

forecast_arima_gas_heat_price_cons <- forecast(auto.arima_gas_heat_price_cons,xreg=gas_heat_price_test, h = 12)
plot(forecast_arima_gas_heat_price_cons)

```

#### Forecasts and predictions

We obtain an error of14% on the train set and 28% on the test set.

```{r accuracy armax gas_heat xreg price}

accuracy_arima.gas_heat <- accuracy (forecast_arima_gas_heat_price_cons, gas_heat_testset)

# store accuracy to create accuracy table

acc_arima_gas_heat_price_MAPE <- accuracy_arima.gas_heat[2,][5]
acc_arima_gas_heat_price_MPE <- accuracy_arima.gas_heat[2,][4]
acc_arima_gas_heat_price_MAE <- accuracy_arima.gas_heat[2,][3]
acc_arima_gas_heat_price_RMSE <- accuracy_arima.gas_heat[2,][2]

```

#### Residuals

Plotting the residuals: we have a spike on lag 19. Consulting Ljung-box test we can say they represent white noise series.  


```{r residuals armax gas_heat xreg price}

res_gas_heat_price_cons <- checkresiduals(auto.arima_gas_heat_price_cons) 

```


### Exponential Smoothing 

Here, we will apply the ETS function. AIC value obtained by this model is: 2553.747. Looking at the summary, we get an information about the error percentage on training set which is about 12.19%.

```{r expo smoothing gas_heat}

es_gas_heat_cons_model <- ets(gas_heat_trainset)  
summary(es_gas_heat_cons_model)

AIC_es_gas_heat_cons_model <- AIC(es_gas_heat_cons_model)

```

Let's try to fit and forecast the model. Looking at the fitted values, seems that is able to capture the shape of our data, also Covid period.


```{r fit expo smoothing gas_heat}
# fit and plot the result 
fit_gas_heat_cons_model <- fitted(es_gas_heat_cons_model)

plot(gas_heat_trainset)
lines(fitted(es_gas_heat_cons_model), col=2)

#forecast and plot the result

forecast_es_gas_heat_cons_model <- forecast(es_gas_heat_cons_model, h = 12)
plot(forecast_es_gas_heat_cons_model)
```

#### Forecasts and predictions 


According to the accuracy the error on test set is around 12.19% and in test set: 8.9 %.

```{r accuracy expo smoothing gas_heat}
accuracy_es_gas_heat_cons <- accuracy (forecast_es_gas_heat_cons_model, gas_heat_testset)

# store accuracy to create accuracy table

acc_es_gas_heat_cons_MAPE <- accuracy_es_gas_heat_cons[2,][5]
acc_es_gas_heat_cons_MPE <- accuracy_es_gas_heat_cons[2,][4]
acc_es_gas_heat_cons_MAE <- accuracy_es_gas_heat_cons[2,][3]
acc_es_gas_heat_cons_RMSE <- accuracy_es_gas_heat_cons[2,][2]
```

#### Residuals

We have important spikes at lag 3, 4 and 23. Also, Ljung-Box confirms that the residuals are not white noise. !!! double check !!!

```{r residuals expo smoothing gas_heat}

checkresiduals(es_gas_heat_cons_model)

```


### GAM MODEL

Add comment for GAM MODEL. AIC Value 2413.009;

```{r GAM gas_heat}
tt<- (1:length(gas_heat_trainset))
seas <- factor(c(rep(1:12,length(gas_heat_trainset)/12)))

g1 <- gam(gas_heat_trainset~s(tt)+seas)

plot(g1, se=T)

AIC(g1)

```


### Summarizing all the models

```{r summary gas_heat}
# AIC plus accuracy table GPL

gas_heat_summary <- matrix(c(
  AIC_arima.gas_heat,AIC_gas_heat_linearModel, AIC_arima.gas_heat_price, AIC_es_gas_heat_cons_model,
  acc_arima_gas_heat_MAPE,acc_lm_gas_heat_MAPE,acc_arima_gas_heat_price_MAPE,acc_es_gas_heat_cons_MAPE,
  acc_arima_gas_heat_MPE,acc_lm_gas_heat_MPE,acc_arima_gas_heat_price_MPE,acc_es_gas_heat_cons_MPE,
  acc_arima_gas_heat_MAE,acc_lm_gas_heat_MAE,acc_arima_gas_heat_price_MAE,acc_es_gas_heat_cons_MAE,
  acc_arima_gas_heat_RMSE,acc_lm_gas_heat_RMSE,acc_arima_gas_heat_price_RMSE,acc_es_gas_heat_cons_RMSE
  )
  
  , ncol = 4, byrow =TRUE)

colnames(gas_heat_summary) <- c('Arima','Linear Model','SARMAX Price', 'ES')
rownames(gas_heat_summary) <- c('AIC', 'MAPE','MPE','MAE','RMSE')

gas_heat_summary <- as.table(gas_heat_summary)
gas_heat_summary

```